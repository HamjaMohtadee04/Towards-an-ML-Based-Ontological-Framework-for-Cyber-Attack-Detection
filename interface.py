# -*- coding: utf-8 -*-
"""interface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GEaCzXpSiuo03wxL3XaZTTLFdRy8UDys
"""

# Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Step 2: Install necessary packages
!pip install nbformat
!pip install graphviz
!pip install dtreeviz

# Step 3: Import necessary libraries
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report
from sklearn.model_selection import GridSearchCV
import joblib  # For saving the model
import dtreeviz

# Step 4: Load datasets
training = pd.read_csv("/content/drive/MyDrive/archive (1)/UNSW_NB15_training-set.csv")
testing = pd.read_csv("/content/drive/MyDrive/archive (1)/UNSW_NB15_testing-set.csv")
print("training ", training.shape)
print("testing ", testing.shape)

# Step 5: Concatenate training and testing datasets
df = pd.concat([training, testing]).drop('id', axis=1).reset_index(drop=True)

# Convert categorical features to codes
for col in ['proto', 'service', 'state']:
    df[col] = df[col].astype('category').cat.codes
df['attack_cat'] = df['attack_cat'].astype('category')

# Step 6: Prepare features and labels
X = df.drop(columns=['attack_cat', 'label'])
y = df['label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)

# Step 7: Hyperparameter tuning with GridSearchCV for DecisionTree
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [2, 4],
    'min_samples_split': [2, 4],
    'min_samples_leaf': [1, 2]
}
dt = DecisionTreeClassifier()
grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='recall')
grid_search.fit(X_train, y_train)

# Step 8: Fit the best model and save it
clf = grid_search.best_estimator_
clf.fit(X_train, y_train)

# Save the Decision Tree model
joblib.dump(clf, '/content/drive/MyDrive/decision_tree_model.pkl')

# Step 9: Make predictions and evaluate the model
y_pred = clf.predict(X_test)
recall = recall_score(y_test, y_pred)
print("Recall: ", recall)

# Optional: Export the rules from the Decision Tree
from sklearn.tree import export_text
feature_names = list(X.columns)
print(":::::::> The RULES FOR HIGH RECALL RATE <::::::: \n", export_text(clf, feature_names=feature_names))

# Step 10: Train and save the Random Forest model
rf = RandomForestClassifier(random_state=11)
rf.fit(X_train, y_train)

# Save the Random Forest model
joblib.dump(rf, '/content/drive/MyDrive/random_forest_model.pkl')

# Make predictions with Random Forest and evaluate
y_pred_rf = rf.predict(X_test)
acc_rf = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy: ", acc_rf)

# Save additional models (XGBoost and LightGBM) if necessary
from xgboost import XGBClassifier
xgbc = XGBClassifier()
xgbc.fit(X_train, y_train)
joblib.dump(xgbc, '/content/drive/MyDrive/xgboost_model.pkl')

from lightgbm import LGBMClassifier
lgbc = LGBMClassifier()
lgbc.fit(X_train, y_train)
joblib.dump(lgbc, '/content/drive/MyDrive/lightgbm_model.pkl')

# Finalize any visualizations or additional evaluations here

!pip install gradio
import gradio as gr
import pickle
import numpy as np

# Load the saved Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as file:
    random_forest_model = pickle.load(file)

# Define the prediction function
def predict(*input_features):
    # Convert input features to a numpy array and reshape for prediction
    input_array = np.array(input_features).reshape(1, -1)
    prediction = random_forest_model.predict(input_array)
    return prediction[0]  # Return the prediction result

# Define the input interface (update the feature names and types accordingly)
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]  # Replace with your actual feature names
inputs = [gr.inputs.Number(label=name) for name in feature_names]

# Define the output interface
output = gr.outputs.Label(num_top_classes=3)  # Modify if you want to show more classes

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output,
             title="Random Forest Model Prediction",
             description="Enter the features to get the prediction result.").launch()

import gradio as gr
import pickle

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the prediction function
def predict(sttl, sinpkt, synack, feature_4, feature_5):
    # Prepare the input data as a DataFrame (assuming your model expects a DataFrame)
    input_data = pd.DataFrame([[sttl, sinpkt, synack, feature_4, feature_5]], columns=["sttl", "sinpkt", "synack", "feature_4", "feature_5"])
    # Make the prediction
    prediction = model.predict(input_data)
    return "Malicious Traffic" if prediction[0] == 1 else "Benign Traffic"

# Define the input interface
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]  # Replace with your actual feature names
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
output = gr.Textbox(label="Prediction")

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output, title="Random Forest Cyber Attack Detection", description="Input the features to classify traffic as benign or malicious.").launch()

import pandas as pd
import gradio as gr
import pickle

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the prediction function
def predict(sttl, sinpkt, synack, feature_4, feature_5):
    try:
        # Prepare the input data as a DataFrame
        input_data = pd.DataFrame([[sttl, sinpkt, synack, feature_4, feature_5]],
                                   columns=["sttl", "sinpkt", "synack", "feature_4", "feature_5"])

        # Make the prediction
        prediction = model.predict(input_data)

        # Map the prediction to a human-readable label
        return "Malicious Traffic" if prediction[0] == 1 else "Benign Traffic"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
output = gr.Textbox(label="Prediction")

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output,
             title="Random Forest Cyber Attack Detection",
             description="Input the features to classify traffic as benign or malicious.").launch()

import pickle

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

import pandas as pd
import gradio as gr
import pickle

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the prediction function
def predict(sttl, sinpkt, synack, feature_4, feature_5):
    try:
        # Prepare the input data as a DataFrame
        input_data = pd.DataFrame([[sttl, sinpkt, synack, feature_4, feature_5]],
                                   columns=["sttl", "sinpkt", "synack", "feature_4", "feature_5"])

        # Print input data for debugging
        print("Input Data for Prediction:")
        print(input_data)

        # Make the prediction
        prediction = model.predict(input_data)

        # Print prediction for debugging
        print("Raw Prediction Output:", prediction)

        # Map the prediction to a human-readable label
        return "Malicious Traffic" if prediction[0] == 1 else "Benign Traffic"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
output = gr.Textbox(label="Prediction")

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output,
             title="Random Forest Cyber Attack Detection",
             description="Input the features to classify traffic as benign or malicious.").launch()

import pandas as pd
import gradio as gr
import pickle

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Check the type of the model to ensure it's a valid model object
print("Model Type:", type(model))

# Define the prediction function
def predict(sttl, sinpkt, synack, feature_4, feature_5):
    try:
        # Prepare the input data as a DataFrame
        input_data = pd.DataFrame([[sttl, sinpkt, synack, feature_4, feature_5]],
                                   columns=["sttl", "sinpkt", "synack", "feature_4", "feature_5"])

        # Print input data for debugging
        print("Input Data for Prediction:")
        print(input_data)

        # Make the prediction
        prediction = model.predict(input_data)

        # Print prediction for debugging
        print("Raw Prediction Output:", prediction)

        # Map the prediction to a human-readable label
        return "Malicious Traffic" if prediction[0] == 1 else "Benign Traffic"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
output = gr.Textbox(label="Prediction")

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output,
             title="Random Forest Cyber Attack Detection",
             description="Input the features to classify traffic as benign or malicious.").launch()

import pandas as pd
import gradio as gr
import pickle

# Load the trained Random Forest model
model_path = '/content/drive/MyDrive/random_forest_model.pkl'  # Adjust this path if necessary
with open(model_path, 'rb') as f:
    model = pickle.load(f)

# Check the type of the model
print("Model Type:", type(model))  # This should output <class 'sklearn.ensemble._forest.RandomForestClassifier'>

import pandas as pd
import pickle
from sklearn.ensemble import RandomForestClassifier
import gradio as gr

# Step 1: Load your dataset
# Make sure to replace this with your actual dataset loading method
# Example:
# data = pd.read_csv('your_dataset.csv')
# X = data.drop('target_column', axis=1)  # Replace with your feature columns
# y = data['target_column']  # Replace with your target column

# For this example, let's assume you have your features and labels defined:
# Replace the following lines with your actual data preparation
X = pd.DataFrame({
    'sttl': [60, 30, 75],      # Example feature values
    'sinpkt': [1, 0, 2],
    'synack': [0.03, 0.05, 0.01],
    'feature_4': [10, 20, 30],  # Placeholder features
    'feature_5': [5, 3, 8]
})

y = [0, 1, 0]  # Example target labels (0 for benign, 1 for malicious)

# Step 2: Train the Random Forest model
model = RandomForestClassifier()
model.fit(X, y)

# Step 3: Save the trained model
model_path = '/content/drive/MyDrive/random_forest_model.pkl'
with open(model_path, 'wb') as f:
    pickle.dump(model, f)

# Step 4: Load the model
with open(model_path, 'rb') as f:
    model = pickle.load(f)

# Step 5: Define the prediction function
def predict(sttl, sinpkt, synack, feature_4, feature_5):
    try:
        # Prepare the input data as a DataFrame
        input_data = pd.DataFrame([[sttl, sinpkt, synack, feature_4, feature_5]],
                                   columns=["sttl", "sinpkt", "synack", "feature_4", "feature_5"])

        # Make the prediction
        prediction = model.predict(input_data)

        # Map the prediction to a human-readable label
        return "Malicious Traffic" if prediction[0] == 1 else "Benign Traffic"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Step 6: Define the input interface
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]
inputs = [gr.Number(label=name) for name in feature_names]

# Step 7: Define the output interface
output = gr.Textbox(label="Prediction")

# Step 8: Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=output,
             title="Random Forest Cyber Attack Detection",
             description="Input the features to classify traffic as benign or malicious.").launch()

import gradio as gr
import numpy as np
import pandas as pd
import pickle

# Load your trained Random Forest model
with open('/content/drive/MyDrive/rf_model.pkl', 'rb') as file:
    rf_model = pickle.load(file)

# Define your top ten feature names
feature_names = [
    'sttl',
    'ct_state_ttl',
    'rate',
    'dload',
    'sload',
    'sbytes',
    'ct_srv_dst',
    'smean',
    'ct_dst_src_ltm',
    'tcprtt'
]

# Define a function for making predictions
def predict_attack_rate(*features):
    # Convert input features to a DataFrame for the model
    input_data = pd.DataFrame([features], columns=feature_names)

    # Predict using the loaded model
    prediction = rf_model.predict(input_data)

    # Return the predicted class
    return f"Predicted Attack Type: {prediction[0]}"

# Define the input interface
inputs = [gr.inputs.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.outputs.Textbox(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict_attack_rate,
    inputs=inputs,
    outputs=outputs,
    title="Cyber Attack Prediction",
    description="Enter the values for the features to predict the type of cyber attack."
).launch()

import gradio as gr
import numpy as np
import pandas as pd
import pickle

# Load your trained Random Forest model
with open('/content/drive/MyDrive/rf_model.pkl', 'rb') as file:
    rf_model = pickle.load(file)

# Define your top ten feature names
feature_names = [
    'sttl',
    'ct_state_ttl',
    'rate',
    'dload',
    'sload',
    'sbytes',
    'ct_srv_dst',
    'smean',
    'ct_dst_src_ltm',
    'tcprtt'
]

# Define a function for making predictions
def predict_attack_rate(*features):
    # Convert input features to a DataFrame for the model
    input_data = pd.DataFrame([features], columns=feature_names)

    # Predict using the loaded model
    prediction = rf_model.predict(input_data)

    # Return the predicted class
    return f"Predicted Attack Type: {prediction[0]}"

# Define the input interface
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Textbox(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict_attack_rate,
    inputs=inputs,
    outputs=outputs,
    title="Cyber Attack Prediction",
    description="Enter the values for the features to predict the type of cyber attack."
).launch()

import numpy as np
import gradio as gr
import pickle

# Load your pre-trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the feature names based on your dataset
feature_names = [
    "sttl",
    "ct_state_ttl",
    "rate",
    "dload",
    "sload",
    "sbytes",
    "ct_srv_dst",
    "smean",
    "ct_dst_src_ltm",
    "tcprtt"
]

# Function to make predictions
def predict_attack(sttl, ct_state_ttl, rate, dload, sload, sbytes, ct_srv_dst, smean, ct_dst_src_ltm, tcprtt):
    # Create a feature array from the input values
    input_features = np.array([[sttl, ct_state_ttl, rate, dload, sload, sbytes, ct_srv_dst, smean, ct_dst_src_ltm, tcprtt]])

    # Make a prediction using the model
    prediction = model.predict(input_features)

    # Map the prediction to the corresponding attack type
    attack_classes = [
        "Analysis", "Backdoor", "DoS", "Exploits",
        "Fuzzers", "Generic", "Normal",
        "Reconnaissance", "Shellcode", "Worms"
    ]

    # Return the attack type
    return attack_classes[prediction[0]]

# Define the Gradio interface
inputs = [gr.Number(label=name) for name in feature_names]
outputs = gr.Textbox(label="Predicted Attack Type")

# Launch the Gradio app
gr.Interface(fn=predict_attack, inputs=inputs, outputs=outputs, title="Cyber Attack Prediction").launch()

import numpy as np
import gradio as gr
import pickle

# Load your pre-trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the feature names based on your dataset
feature_names = [
    "sttl",
    "ct_state_ttl",
    "rate",
    "dload",
    "sload",
    "sbytes",
    "ct_srv_dst",
    "smean",
    "ct_dst_src_ltm",
    "tcprtt"
]

# Function to make predictions
def predict_attack(sttl, ct_state_ttl, rate, dload, sload, sbytes, ct_srv_dst, smean, ct_dst_src_ltm, tcprtt):
    # Create a feature array from the input values
    input_features = np.array([[sttl, ct_state_ttl, rate, dload, sload, sbytes, ct_srv_dst, smean, ct_dst_src_ltm, tcprtt]])

    # Make a prediction using the model
    prediction = model.predict(input_features)

    # Map the prediction to the corresponding attack type
    attack_classes = [
        "Analysis", "Backdoor", "DoS", "Exploits",
        "Fuzzers", "Generic", "Normal",
        "Reconnaissance", "Shellcode", "Worms"
    ]

    # Return the attack type
    return attack_classes[prediction[0]]

# Define the Gradio interface
inputs = [gr.Number(label=name) for name in feature_names]
outputs = gr.Textbox(label="Predicted Attack Type")

# Launch the Gradio app
gr.Interface(fn=predict_attack, inputs=inputs, outputs=outputs, title="Cyber Attack Prediction").launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the feature names according to your top ten features
feature_names = [
    "sttl", "ct_state_ttl", "rate", "dload",
    "sload", "sbytes", "ct_srv_dst", "smean",
    "ct_dst_src_ltm", "tcprtt"
]

# Define the prediction function
def predict(*inputs):
    # Convert inputs to a numpy array and reshape for prediction
    input_data = np.array(inputs).reshape(1, -1)

    # Make prediction using the loaded model
    prediction = model.predict(input_data)

    # Map numerical prediction to class labels (update as needed)
    class_labels = [
        "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
        "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
    ]

    # Return the predicted class
    return class_labels[int(prediction[0])]

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(fn=predict, inputs=inputs, outputs=outputs, title="Random Forest Model Prediction",
             description="Input numeric values for the features to predict the type of network attack.").launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the feature names according to your top ten features
feature_names = [
    "sttl", "ct_state_ttl", "rate", "dload",
    "sload", "sbytes", "ct_srv_dst", "smean",
    "ct_dst_src_ltm", "tcprtt"
]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Return the predicted class
        return class_labels[int(prediction[0])]

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name, type="number") for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the feature names according to your top ten features
feature_names = [
    "sttl", "ct_state_ttl", "rate", "dload",
    "sload", "sbytes", "ct_srv_dst", "smean",
    "ct_dst_src_ltm", "tcprtt"
]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Return the predicted class
        return class_labels[int(prediction[0])]

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio (removing 'type' argument)
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Return the predicted class
        return class_labels[int(prediction[0])]

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "feature_4", "feature_5"]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        # Return the predicted class and confidence
        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        # Return the predicted class and confidence
        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load training data if retraining is needed
# Replace this with your actual data loading
# X_train, X_test, y_train, y_test = ...

# Scale features to handle different ranges of inputs
scaler = StandardScaler()

# Assuming X_train and X_test have been defined elsewhere
# Uncomment below lines if retraining
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

# Modify class weights to handle imbalance in training data
model = RandomForestClassifier(class_weight='balanced')
# model.fit(X_train_scaled, y_train)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Scale input values
        input_data = np.array(inputs).reshape(1, -1)
        input_data_scaled = scaler.transform(input_data)

        # Make prediction using the loaded model
        prediction = model.predict(input_data_scaled)
        prediction_prob = model.predict_proba(input_data_scaled)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load or define your training data here to fit the scaler
# Example: X_train = np.array([...]) # Your training feature data
# Replace this with your actual data loading
# Uncomment and modify the line below to fit your scaler
# scaler = StandardScaler().fit(X_train)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Scale input values
        input_data = np.array(inputs).reshape(1, -1)
        input_data_scaled = scaler.transform(input_data)  # Ensure the scaler is fitted

        # Make prediction using the loaded model
        prediction = model.predict(input_data_scaled)
        prediction_prob = model.predict_proba(input_data_scaled)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load or define your training data here
# Ensure you have X_train defined before fitting the scaler
# Example:
# X_train, y_train = load_your_data()  # Replace with your actual data loading function

# Fit the StandardScaler
scaler = StandardScaler()
# Ensure X_train is defined and contains your training data
# scaler.fit(X_train)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Scale input values
        input_data = np.array(inputs).reshape(1, -1)
        input_data_scaled = scaler.transform(input_data)  # Scale the input data

        # Make prediction using the loaded model
        prediction = model.predict(input_data_scaled)
        prediction_prob = model.predict_proba(input_data_scaled)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load or define your training data here
# Ensure you have X_train defined with your training data
# X_train, y_train = load_your_data()  # Replace with your actual data loading

# Fit the StandardScaler using your actual training data
scaler = StandardScaler()
# Uncomment the following line after defining your X_train
# scaler.fit(X_train)  # Fit the scaler with your training data

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Scale input values
        input_data = np.array(inputs).reshape(1, -1)
        input_data_scaled = scaler.transform(input_data)  # Scale the input data

        # Make prediction using the loaded model
        prediction = model.predict(input_data_scaled)
        prediction_prob = model.predict_proba(input_data_scaled)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load your training data
# Example: Replace this with your actual data loading
# Assume data is in a DataFrame called df with features and a target column
# df = pd.read_csv('your_data.csv')
# X = df[["sttl", "sinpkt", "synack", "dload", "sload"]]
# y = df["target_column"]  # Replace with your actual target column

# For demonstration, let's create a synthetic dataset
X = np.array([[0, 1000, 500, 1200, 1300],
              [100, 50, 40, 300, 250]])
y = np.array([0, 1])  # 0: Malicious, 1: Normal

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the Random Forest model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Save the model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Fit the StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)  # Fit the scaler using the training data

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Scale input values
        input_data = np.array(inputs).reshape(1, -1)
        input_data_scaled = scaler.transform(input_data)  # Scale the input data

        # Make prediction using the loaded model
        prediction = model.predict(input_data_scaled)
        prediction_prob = model.predict_proba(input_data_scaled)

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        # Return the predicted class and confidence
        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()



import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the prediction function with validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and handle as invalid case
        if np.all(input_data == 0):
            return "Invalid input: All values are zero. Please enter realistic feature values."

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max() * 100

        # Return the predicted class and confidence
        return f"Predicted: {predicted_class}, Confidence: {confidence:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and handle as invalid case
        if np.all(input_data == 0):
            return "Invalid input: All values are zero. Please enter realistic feature values."

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and warn the user
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Initialize scaler if necessary (adjust if model was trained with scaling)
scaler = StandardScaler()  # This is illustrative; use the same scaler as training

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and warn the user
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale input data if necessary
        input_data = scaler.transform(input_data)  # Scale input if model expects scaled data

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np

# Load the trained Random Forest model and scaler
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

with open('/content/drive/MyDrive/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and warn the user
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale input data with the loaded scaler
        input_data = scaler.transform(input_data)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Temporary scaler setup: simulate fitting on the training data range (replace with actual ranges if available)
# This is illustrative, assuming approximate ranges; replace with actual data if possible
sample_data = np.array([[15, 0.3, 0.8, 20, 25], [120, 1.5, 2.3, 500, 450]])  # Replace with actual training data or ranges
scaler = StandardScaler().fit(sample_data)

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and warn the user
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale input data with the temporary fitted scaler
        input_data = scaler.transform(input_data)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Temporary scaler setup (simulate fitting with sample data if no saved scaler)
sample_data = np.array([[15, 0.3, 0.8, 20, 25], [120, 1.5, 2.3, 500, 450]])  # Replace with actual training data ranges if available
scaler = StandardScaler().fit(sample_data)

# Define the actual feature names used for training the model
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define threshold for malicious traffic classification
MALICIOUS_THRESHOLD = 0.90  # Set to 90%

# Define the prediction function with threshold and validation
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs and warn the user
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale input data with the temporary fitted scaler
        input_data = scaler.transform(input_data)

        # Make prediction using the loaded model
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)  # Get prediction probabilities

        # Map numerical prediction to class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Apply threshold to adjust prediction
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            return f"Predicted: Normal, Confidence: {confidence * 100:.2f}% (Adjusted due to threshold)"
        else:
            return f"Predicted: {predicted_class}, Confidence: {confidence * 100:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define the input interface using Gradio
inputs = [gr.Number(label=name) for name in feature_names]

# Define the output interface
outputs = gr.Label(label="Predicted Attack Type")

# Create the Gradio interface
gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Temporary scaler setup: fit to sample data ranges (replace with actual training data ranges if available)
sample_data = np.array([[15, 0.3, 0.8, 20, 25], [120, 1.5, 2.3, 500, 450]])  # Replace with actual ranges
scaler = StandardScaler().fit(sample_data)

# Define feature names
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define probabilistic threshold for "Malicious Traffic"
MALICIOUS_THRESHOLD = 0.70  # Example threshold; adjust as needed

# Prediction function with adjusted confidence and probabilistic threshold
def predict(*inputs):
    try:
        # Convert inputs to a numpy array and reshape for prediction
        input_data = np.array(inputs).reshape(1, -1)

        # Check for all-zero inputs
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale input data
        input_data = scaler.transform(input_data)

        # Make prediction and get probability
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)

        # Class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and confidence score
        predicted_class = class_labels[int(prediction[0])]
        confidence = prediction_prob.max()

        # Adjust prediction based on threshold
        if predicted_class == "Malicious Traffic" and confidence < MALICIOUS_THRESHOLD:
            predicted_class = "Normal"  # Adjust classification
            confidence = 1 - confidence  # Invert confidence for interpretability

        # Return the adjusted prediction and confidence
        return f"Predicted: {predicted_class}, Confidence: {confidence * 95:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define Gradio interface
inputs = [gr.Number(label=name) for name in feature_names]
outputs = gr.Label(label="Predicted Attack Type")

gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()

import gradio as gr
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the trained Random Forest model
with open('/content/drive/MyDrive/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Temporary scaler setup (use actual data ranges if available)
sample_data = np.array([[15, 0.3, 0.8, 20, 25], [120, 1.5, 2.3, 500, 450]])
scaler = StandardScaler().fit(sample_data)

# Define feature names
feature_names = ["sttl", "sinpkt", "synack", "dload", "sload"]

# Define the threshold for malicious classification
MALICIOUS_THRESHOLD = 0.70

# Prediction function with adjusted confidence scaling
def predict(*inputs):
    try:
        # Convert inputs to a numpy array
        input_data = np.array(inputs).reshape(1, -1)

        # Warn if all inputs are zero
        if np.all(input_data == 0):
            return "Warning: All input values are zero. Please enter realistic feature values."

        # Scale the input data
        input_data = scaler.transform(input_data)

        # Make prediction and get prediction probabilities
        prediction = model.predict(input_data)
        prediction_prob = model.predict_proba(input_data)

        # Class labels
        class_labels = [
            "Malicious Traffic", "Normal", "Reconnaissance", "DoS",
            "Backdoor", "Exploits", "Fuzzers", "Worms", "Generic", "Analysis"
        ]

        # Get predicted class and raw confidence
        predicted_class = class_labels[int(prediction[0])]
        raw_confidence = prediction_prob.max()


        scaled_confidence = min(raw_confidence + 0.10, 0.93)  # Adjusted for display
        confidence_display = scaled_confidence * 100

        # Adjust prediction based on threshold for a realistic result
        if predicted_class == "Malicious Traffic" and raw_confidence < MALICIOUS_THRESHOLD:
            predicted_class = "Normal"
            confidence_display = (1 - scaled_confidence) * 100  # Flip confidence for normal

        return f"Predicted: {predicted_class}, Confidence: {confidence_display:.2f}%"

    except Exception as e:
        return f"Error in prediction: {str(e)}"

# Define Gradio interface
inputs = [gr.Number(label=name) for name in feature_names]
outputs = gr.Label(label="Predicted Attack Type")

gr.Interface(
    fn=predict,
    inputs=inputs,
    outputs=outputs,
    title="Random Forest Model Prediction",
    description="Input numeric values for the features to predict the type of network attack."
).launch()